{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb6693e2",
   "metadata": {},
   "source": [
    "## 1) Problem statement.\n",
    "\n",
    "**Data:** Sensor Data\n",
    "\n",
    "**Problem statement :**\n",
    "- The system in focus is the Air Pressure system (APS) which generates pressurized air that are utilized in various functions in a truck, such as braking and gear changes. The datasets positive class corresponds to component failures for a specific component of the APS system. The negative class corresponds to trucks with failures for components not related to the APS system.\n",
    "\n",
    "- The problem is to reduce the cost due to unnecessary repairs. So it is required to minimize the false predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90caa5ed",
   "metadata": {},
   "source": [
    "|True class | Positive | Negative | |\n",
    "| ----------- | ----------- |   |  |\n",
    "|<b>Predicted class</b>||| |\n",
    "| Positive      |   -       | cost_1  |    |\n",
    "| Negative   | cost_2        |  | |\n",
    "\n",
    "\n",
    "Cost 1 = 10 and Cost 2 = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b675b85e",
   "metadata": {},
   "source": [
    "- The total cost of a prediction model the sum of `Cost_1` multiplied by the number of Instances with type 1 failure and `Cost_2` with the number of instances with type 2 failure, resulting in a `Total_cost`. In this case `Cost_1` refers to the cost that an unnessecary check needs to be done by an mechanic at an workshop, while `Cost_2` refer to the cost of missing a faulty truck, which may cause a breakdown. \n",
    "- `Total_cost = Cost_1 * No_Instances + Cost_2 * No_Instances.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05c993",
   "metadata": {},
   "source": [
    "- It is done in order to reduce the False Positive (FP) and False Negative (FN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2ae17",
   "metadata": {},
   "source": [
    "## 2) Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa51c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f0c9c",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "588ad50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('aps_failure_training_set1.csv',na_values='na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08f80fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>153204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129862.0</td>\n",
       "      <td>26872.0</td>\n",
       "      <td>34044.0</td>\n",
       "      <td>22472.0</td>\n",
       "      <td>34362.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>453236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7908038.0</td>\n",
       "      <td>3026002.0</td>\n",
       "      <td>5025350.0</td>\n",
       "      <td>2025766.0</td>\n",
       "      <td>1160638.0</td>\n",
       "      <td>533834.0</td>\n",
       "      <td>493800.0</td>\n",
       "      <td>6914.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>72504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>178226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1432098.0</td>\n",
       "      <td>372252.0</td>\n",
       "      <td>527514.0</td>\n",
       "      <td>358274.0</td>\n",
       "      <td>332818.0</td>\n",
       "      <td>284178.0</td>\n",
       "      <td>3742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>762958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>776.0</td>\n",
       "      <td>281128.0</td>\n",
       "      <td>2186308.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos</td>\n",
       "      <td>695994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1397742.0</td>\n",
       "      <td>495544.0</td>\n",
       "      <td>361646.0</td>\n",
       "      <td>28610.0</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pos</td>\n",
       "      <td>1056758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42328.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50394.0</td>\n",
       "      <td>184552.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1450086.0</td>\n",
       "      <td>713608.0</td>\n",
       "      <td>1750894.0</td>\n",
       "      <td>4054554.0</td>\n",
       "      <td>4096660.0</td>\n",
       "      <td>2295880.0</td>\n",
       "      <td>220478.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pos</td>\n",
       "      <td>361638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>266410.0</td>\n",
       "      <td>114746.0</td>\n",
       "      <td>180006.0</td>\n",
       "      <td>108294.0</td>\n",
       "      <td>111218.0</td>\n",
       "      <td>264410.0</td>\n",
       "      <td>33734.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pos</td>\n",
       "      <td>791254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14868.0</td>\n",
       "      <td>921256.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3625532.0</td>\n",
       "      <td>1380864.0</td>\n",
       "      <td>3262488.0</td>\n",
       "      <td>5727988.0</td>\n",
       "      <td>7563752.0</td>\n",
       "      <td>12114820.0</td>\n",
       "      <td>264714.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pos</td>\n",
       "      <td>1053152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7093206.0</td>\n",
       "      <td>3379622.0</td>\n",
       "      <td>7362340.0</td>\n",
       "      <td>8442584.0</td>\n",
       "      <td>8120144.0</td>\n",
       "      <td>5082396.0</td>\n",
       "      <td>6259760.0</td>\n",
       "      <td>176752.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pos</td>\n",
       "      <td>785270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8994.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class   aa_000  ab_000   ac_000  ad_000  ae_000  af_000  ag_000    ag_001  \\\n",
       "0   pos   153204     0.0    182.0     NaN     0.0     0.0     0.0       0.0   \n",
       "1   pos   453236     NaN   2926.0     NaN     0.0     0.0     0.0       0.0   \n",
       "2   pos    72504     NaN   1594.0  1052.0     0.0     0.0     0.0     244.0   \n",
       "3   pos   762958     NaN      NaN     NaN     NaN     NaN   776.0  281128.0   \n",
       "4   pos   695994     NaN      NaN     NaN     NaN     NaN     0.0       0.0   \n",
       "5   pos  1056758     0.0  42328.0   856.0     0.0     0.0     0.0   50394.0   \n",
       "6   pos   361638     0.0    280.0     NaN     0.0     0.0     0.0       0.0   \n",
       "7   pos   791254     NaN      NaN     NaN     NaN     NaN     0.0   14868.0   \n",
       "8   pos  1053152     NaN      NaN     NaN     NaN     NaN     2.0       2.0   \n",
       "9   pos   785270     NaN      NaN  8994.0     NaN     NaN     0.0       0.0   \n",
       "\n",
       "      ag_002  ...     ee_002     ee_003     ee_004     ee_005     ee_006  \\\n",
       "0        0.0  ...   129862.0    26872.0    34044.0    22472.0    34362.0   \n",
       "1      222.0  ...  7908038.0  3026002.0  5025350.0  2025766.0  1160638.0   \n",
       "2   178226.0  ...  1432098.0   372252.0   527514.0   358274.0   332818.0   \n",
       "3  2186308.0  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "4        0.0  ...  1397742.0   495544.0   361646.0    28610.0     5130.0   \n",
       "5   184552.0  ...  1450086.0   713608.0  1750894.0  4054554.0  4096660.0   \n",
       "6        0.0  ...   266410.0   114746.0   180006.0   108294.0   111218.0   \n",
       "7   921256.0  ...  3625532.0  1380864.0  3262488.0  5727988.0  7563752.0   \n",
       "8       30.0  ...  7093206.0  3379622.0  7362340.0  8442584.0  8120144.0   \n",
       "9        0.0  ...        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "       ee_007     ee_008    ee_009  ef_000  eg_000  \n",
       "0         0.0        0.0       0.0     0.0     0.0  \n",
       "1    533834.0   493800.0    6914.0     0.0     0.0  \n",
       "2    284178.0     3742.0       0.0     0.0     0.0  \n",
       "3         NaN        NaN       NaN     NaN     NaN  \n",
       "4       212.0        0.0       0.0     NaN     NaN  \n",
       "5   2295880.0   220478.0     482.0     0.0     0.0  \n",
       "6    264410.0    33734.0       0.0     0.0     0.0  \n",
       "7  12114820.0   264714.0     198.0     NaN     NaN  \n",
       "8   5082396.0  6259760.0  176752.0     NaN     NaN  \n",
       "9         0.0        0.0       0.0     NaN     NaN  \n",
       "\n",
       "[10 rows x 171 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c8dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36188, 171)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape (count of rows and columns) of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4982789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "neg    35188\n",
       "pos     1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the unique values of target variable (binary classification)\n",
    "\n",
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bdeb510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 170 numerical features: ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n",
      "\n",
      "We have 1 categorical features: ['class']\n"
     ]
    }
   ],
   "source": [
    "# Define the numerical and categorical columns from the dataset\n",
    "numerical_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']\n",
    "\n",
    "# Print the numerical and categorical columns\n",
    "print('We have {} numerical features: {}'.format(len(numerical_features), numerical_features))\n",
    "print('\\nWe have {} categorical features: {}'.format(len(categorical_features), categorical_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae320c7",
   "metadata": {},
   "source": [
    "##### As this is a sensor data. Interpretation of the data is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064bb4f3",
   "metadata": {},
   "source": [
    "## Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc79ccc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class         0\n",
       "aa_000        0\n",
       "ab_000    27896\n",
       "ac_000     2141\n",
       "ad_000     9200\n",
       "          ...  \n",
       "ee_007      379\n",
       "ee_008      379\n",
       "ee_009      379\n",
       "ef_000     1730\n",
       "eg_000     1729\n",
       "Length: 171, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44041d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot missing values count for each of the columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (20,15))\n",
    "\n",
    "missing = df.isna().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending = False)\n",
    "\n",
    "ax.bar(missing.index, missing.values.T[0])\n",
    "plt.xticks([])\n",
    "plt.ylabel('Percentage Missing')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e871c",
   "metadata": {},
   "source": [
    "Here we can see that there are a lot of missing values present in each of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604060e9",
   "metadata": {},
   "source": [
    "## Drop those columns which has more than 70% of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a53600e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br_000</th>\n",
       "      <td>81.410965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bq_000</th>\n",
       "      <td>80.501824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp_000</th>\n",
       "      <td>78.794075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_000</th>\n",
       "      <td>77.086327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cr_000</th>\n",
       "      <td>77.086327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo_000</th>\n",
       "      <td>76.533658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn_000</th>\n",
       "      <td>72.761689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "br_000  81.410965\n",
       "bq_000  80.501824\n",
       "bp_000  78.794075\n",
       "ab_000  77.086327\n",
       "cr_000  77.086327\n",
       "bo_000  76.533658\n",
       "bn_000  72.761689"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop those columns which has more than 70% of missing values\n",
    "\n",
    "drop_cols = missing[missing[0]>70]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fce11190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(drop_cols.index), axis = 1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522ade5",
   "metadata": {},
   "source": [
    "Now you can see that 7 columns has been dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ff2d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36188, 164)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab2afd1",
   "metadata": {},
   "source": [
    "the columns count has been dropped from 171 -> 164."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29820f",
   "metadata": {},
   "source": [
    "### Check the total percentage of missing values of full dataset after dropping columns with more than 70% of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16e981e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of total missing cells in the data 5.37059852747306%\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "#percent of data that is missing\n",
    "print(f'Percentage of total missing cells in the data {(total_missing/total_cells) * 100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88ef2b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHqCAYAAADLbQ06AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzzUlEQVR4nO3dfVCU973//9cWZIMEtiDCQkMce1SOFE1OMQE0TYw3oBWJSSba0rOVE4JJUSgVRmvaNKZjpMYkJq3fYz05thprQzq1JumIFNpUW6J4wwlVvItNTcQJiNVlEUoWgvv7I831c8EYQ9D9WJ+PmZ3JXtd7dz8XczzPXrt7gc3n8/kEAACM9LlALwAAAHw8Qg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFAPIJ/Pp7a2NvE7ZAAAA4VQD6Bz587J4XDo3LlzgV4KAOBfBKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBgAQ31mjVrNHbsWEVERCgiIkLp6enatm2btT83N1c2m83vlpaW5vccXq9XhYWFio6OVlhYmLKzs3Xy5Em/GbfbLZfLJYfDIYfDIZfLpdbWVr+ZEydOaObMmQoLC1N0dLSKiorU1dV1xY4dAIDLEdBQ33TTTfrRj36kffv2ad++fZo0aZLuueceHTx40JqZNm2ampqarFtFRYXfcxQXF2vLli0qLy9XTU2N2tvblZWVpZ6eHmsmJydH9fX1qqysVGVlperr6+Vyuaz9PT09mjFjhjo6OlRTU6Py8nJt3rxZJSUlV/6HAADAJdh8Pp8v0Iu4UFRUlFauXKm8vDzl5uaqtbVVr7zyykVnPR6Phg4dqo0bN2rOnDmSpPfee08JCQmqqKhQZmamDh8+rKSkJNXW1io1NVWSVFtbq/T0dB05ckSJiYnatm2bsrKy1NjYqPj4eElSeXm5cnNz1dLSooiIiMtae1tbmxwOhzwez2U/BsCnt3jdoUAvAdehFXlJAXldYz6j7unpUXl5uTo6OpSenm5t3759u2JiYjRq1Cjl5+erpaXF2ldXV6fu7m5lZGRY2+Lj45WcnKydO3dKknbt2iWHw2FFWpLS0tLkcDj8ZpKTk61IS1JmZqa8Xq/q6uo+ds1er1dtbW1+NwAABlLAQ33gwAHdeOONstvteuSRR7RlyxYlJX34v1qmT5+uTZs26fXXX9czzzyjvXv3atKkSfJ6vZKk5uZmhYSEKDIy0u85Y2Nj1dzcbM3ExMT0ed2YmBi/mdjYWL/9kZGRCgkJsWYupqyszPrc2+FwKCEhof8/CAAALiI40AtITExUfX29WltbtXnzZs2dO1c7duxQUlKS9Xa2JCUnJ2vcuHEaNmyYtm7dqvvuu+9jn9Pn88lms1n3L/zvzzLT25IlS7Rw4ULrfltbG7EGAAyogJ9Rh4SEaMSIERo3bpzKysp0yy236Pnnn7/obFxcnIYNG6Zjx45JkpxOp7q6uuR2u/3mWlparDNkp9OpU6dO9Xmu06dP+830PnN2u93q7u7uc6Z9Ibvdbn1j/aMbAAADKeCh7s3n81lvbfd25swZNTY2Ki4uTpKUkpKiQYMGqbq62pppampSQ0ODxo8fL0lKT0+Xx+PRnj17rJndu3fL4/H4zTQ0NKipqcmaqaqqkt1uV0pKyoAfIwAAlyugb30/+uijmj59uhISEnTu3DmVl5dr+/btqqysVHt7u5YuXar7779fcXFxeuedd/Too48qOjpa9957ryTJ4XAoLy9PJSUlGjJkiKKiolRaWqoxY8ZoypQpkqTRo0dr2rRpys/P19q1ayVJ8+bNU1ZWlhITEyVJGRkZSkpKksvl0sqVK3X27FmVlpYqPz+fs2QAQEAFNNSnTp2Sy+VSU1OTHA6Hxo4dq8rKSk2dOlWdnZ06cOCAXnzxRbW2tiouLk533323Xn75ZYWHh1vPsWrVKgUHB2v27Nnq7OzU5MmTtX79egUFBVkzmzZtUlFRkfXt8OzsbK1evdraHxQUpK1bt6qgoEATJkxQaGiocnJy9PTTT1+9HwYAABdh3HXU1zKuowauDq6jRiBc99dRAwCAvgg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABiMUAMAYDBCDQCAwQg1AAAGI9QAABgsoKFes2aNxo4dq4iICEVERCg9PV3btm2z9vt8Pi1dulTx8fEKDQ3VxIkTdfDgQb/n8Hq9KiwsVHR0tMLCwpSdna2TJ0/6zbjdbrlcLjkcDjkcDrlcLrW2tvrNnDhxQjNnzlRYWJiio6NVVFSkrq6uK3bsAABcjoCG+qabbtKPfvQj7du3T/v27dOkSZN0zz33WDF+6qmn9Oyzz2r16tXau3evnE6npk6dqnPnzlnPUVxcrC1btqi8vFw1NTVqb29XVlaWenp6rJmcnBzV19ersrJSlZWVqq+vl8vlsvb39PRoxowZ6ujoUE1NjcrLy7V582aVlJRcvR8GAAAXYfP5fL5AL+JCUVFRWrlypR588EHFx8eruLhYixcvlvTh2XNsbKxWrFihhx9+WB6PR0OHDtXGjRs1Z84cSdJ7772nhIQEVVRUKDMzU4cPH1ZSUpJqa2uVmpoqSaqtrVV6erqOHDmixMREbdu2TVlZWWpsbFR8fLwkqby8XLm5uWppaVFERMRlrb2trU0Oh0Mej+eyHwPg01u87lCgl4Dr0Iq8pIC8rjGfUff09Ki8vFwdHR1KT0/X8ePH1dzcrIyMDGvGbrfrrrvu0s6dOyVJdXV16u7u9puJj49XcnKyNbNr1y45HA4r0pKUlpYmh8PhN5OcnGxFWpIyMzPl9XpVV1f3sWv2er1qa2vzuwEAMJACHuoDBw7oxhtvlN1u1yOPPKItW7YoKSlJzc3NkqTY2Fi/+djYWGtfc3OzQkJCFBkZecmZmJiYPq8bExPjN9P7dSIjIxUSEmLNXExZWZn1ubfD4VBCQsKnPHoAAC4t4KFOTExUfX29amtr9a1vfUtz587VoUP//9taNpvNb97n8/XZ1lvvmYvN92emtyVLlsjj8Vi3xsbGS64LAIBPK+ChDgkJ0YgRIzRu3DiVlZXplltu0fPPPy+n0ylJfc5oW1parLNfp9Oprq4uud3uS86cOnWqz+uePn3ab6b367jdbnV3d/c5076Q3W63vrH+0Q0AgIEU8FD35vP55PV6NXz4cDmdTlVXV1v7urq6tGPHDo0fP16SlJKSokGDBvnNNDU1qaGhwZpJT0+Xx+PRnj17rJndu3fL4/H4zTQ0NKipqcmaqaqqkt1uV0pKyhU9XgAALiU4kC/+6KOPavr06UpISNC5c+dUXl6u7du3q7KyUjabTcXFxVq+fLlGjhypkSNHavny5Ro8eLBycnIkSQ6HQ3l5eSopKdGQIUMUFRWl0tJSjRkzRlOmTJEkjR49WtOmTVN+fr7Wrl0rSZo3b56ysrKUmJgoScrIyFBSUpJcLpdWrlyps2fPqrS0VPn5+ZwlAwACKqChPnXqlFwul5qamuRwODR27FhVVlZq6tSpkqRFixaps7NTBQUFcrvdSk1NVVVVlcLDw63nWLVqlYKDgzV79mx1dnZq8uTJWr9+vYKCgqyZTZs2qaioyPp2eHZ2tlavXm3tDwoK0tatW1VQUKAJEyYoNDRUOTk5evrpp6/STwIAgIsz7jrqaxnXUQNXB9dRIxCu++uoAQBAX4QaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDEWoAAAxGqAEAMBihBgDAYIQaAACDBTTUZWVluu222xQeHq6YmBjNmjVLR48e9ZvJzc2VzWbzu6WlpfnNeL1eFRYWKjo6WmFhYcrOztbJkyf9Ztxut1wulxwOhxwOh1wul1pbW/1mTpw4oZkzZyosLEzR0dEqKipSV1fXFTl2AAAuR0BDvWPHDs2fP1+1tbWqrq7WBx98oIyMDHV0dPjNTZs2TU1NTdatoqLCb39xcbG2bNmi8vJy1dTUqL29XVlZWerp6bFmcnJyVF9fr8rKSlVWVqq+vl4ul8va39PToxkzZqijo0M1NTUqLy/X5s2bVVJScmV/CAAAXILN5/P5Ar2Ij5w+fVoxMTHasWOH7rzzTkkfnlG3trbqlVdeuehjPB6Phg4dqo0bN2rOnDmSpPfee08JCQmqqKhQZmamDh8+rKSkJNXW1io1NVWSVFtbq/T0dB05ckSJiYnatm2bsrKy1NjYqPj4eElSeXm5cnNz1dLSooiIiE9cf1tbmxwOhzwez2XNA+ifxesOBXoJuA6tyEsKyOsa9Rm1x+ORJEVFRflt3759u2JiYjRq1Cjl5+erpaXF2ldXV6fu7m5lZGRY2+Lj45WcnKydO3dKknbt2iWHw2FFWpLS0tLkcDj8ZpKTk61IS1JmZqa8Xq/q6uoG/mABALgMwYFewEd8Pp8WLlyoO+64Q8nJydb26dOn64EHHtCwYcN0/PhxPfbYY5o0aZLq6upkt9vV3NyskJAQRUZG+j1fbGysmpubJUnNzc2KiYnp85oxMTF+M7GxsX77IyMjFRISYs305vV65fV6rfttbW39O3gAAD6GMaFesGCB9u/fr5qaGr/tH72dLUnJyckaN26chg0bpq1bt+q+++772Ofz+Xyy2WzW/Qv/+7PMXKisrExPPPHExx8UAACfkRFvfRcWFuq1117TH//4R910002XnI2Li9OwYcN07NgxSZLT6VRXV5fcbrffXEtLi3WG7HQ6derUqT7Pdfr0ab+Z3mfObrdb3d3dfc60P7JkyRJ5PB7r1tjYeHkHDADAZQpoqH0+nxYsWKDf/OY3ev311zV8+PBPfMyZM2fU2NiouLg4SVJKSooGDRqk6upqa6apqUkNDQ0aP368JCk9PV0ej0d79uyxZnbv3i2Px+M309DQoKamJmumqqpKdrtdKSkpF12L3W5XRESE3w0AgIEU0Le+58+fr1/+8pd69dVXFR4ebp3ROhwOhYaGqr29XUuXLtX999+vuLg4vfPOO3r00UcVHR2te++915rNy8tTSUmJhgwZoqioKJWWlmrMmDGaMmWKJGn06NGaNm2a8vPztXbtWknSvHnzlJWVpcTERElSRkaGkpKS5HK5tHLlSp09e1alpaXKz88nwACAgAnoGfWaNWvk8Xg0ceJExcXFWbeXX35ZkhQUFKQDBw7onnvu0ahRozR37lyNGjVKu3btUnh4uPU8q1at0qxZszR79mxNmDBBgwcP1m9/+1sFBQVZM5s2bdKYMWOUkZGhjIwMjR07Vhs3brT2BwUFaevWrbrhhhs0YcIEzZ49W7NmzdLTTz999X4gAAD0YtR11Nc6rqMGrg6uo0YgcB01AADog1ADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMECGuqysjLddtttCg8PV0xMjGbNmqWjR4/6zfh8Pi1dulTx8fEKDQ3VxIkTdfDgQb8Zr9erwsJCRUdHKywsTNnZ2Tp58qTfjNvtlsvlksPhkMPhkMvlUmtrq9/MiRMnNHPmTIWFhSk6OlpFRUXq6uq6IscOAMDlCGiod+zYofnz56u2tlbV1dX64IMPlJGRoY6ODmvmqaee0rPPPqvVq1dr7969cjqdmjp1qs6dO2fNFBcXa8uWLSovL1dNTY3a29uVlZWlnp4eayYnJ0f19fWqrKxUZWWl6uvr5XK5rP09PT2aMWOGOjo6VFNTo/Lycm3evFklJSVX54cBAMBF2Hw+ny/Qi/jI6dOnFRMTox07dujOO++Uz+dTfHy8iouLtXjxYkkfnj3HxsZqxYoVevjhh+XxeDR06FBt3LhRc+bMkSS99957SkhIUEVFhTIzM3X48GElJSWptrZWqampkqTa2lqlp6fryJEjSkxM1LZt25SVlaXGxkbFx8dLksrLy5Wbm6uWlhZFRER84vrb2trkcDjk8Xguax5A/yxedyjQS8B1aEVeUkBe16jPqD0ejyQpKipKknT8+HE1NzcrIyPDmrHb7brrrru0c+dOSVJdXZ26u7v9ZuLj45WcnGzN7Nq1Sw6Hw4q0JKWlpcnhcPjNJCcnW5GWpMzMTHm9XtXV1V2hIwYA4NKCA72Aj/h8Pi1cuFB33HGHkpOTJUnNzc2SpNjYWL/Z2NhYvfvuu9ZMSEiIIiMj+8x89Pjm5mbFxMT0ec2YmBi/md6vExkZqZCQEGumN6/XK6/Xa91va2u77OMFAOBy9OuMetKkSX2+iCV9GKpJkyb1ayELFizQ/v379dJLL/XZZ7PZ/O77fL4+23rrPXOx+f7MXKisrMz6cprD4VBCQsIl1wQAwKfVr1Bv3779ot+Gfv/99/XnP//5Uz9fYWGhXnvtNf3xj3/UTTfdZG13Op2S1OeMtqWlxTr7dTqd6urqktvtvuTMqVOn+rzu6dOn/WZ6v47b7VZ3d3efM+2PLFmyRB6Px7o1NjZ+msMGAOATfapQ79+/X/v375ckHTp0yLq/f/9+vfnmm1q3bp2+8IUvXPbz+Xw+LViwQL/5zW/0+uuva/jw4X77hw8fLqfTqerqamtbV1eXduzYofHjx0uSUlJSNGjQIL+ZpqYmNTQ0WDPp6enyeDzas2ePNbN79255PB6/mYaGBjU1NVkzVVVVstvtSklJuej67Xa7IiIi/G4AAAykT/UZ9a233iqbzSabzXbRt7hDQ0P1k5/85LKfb/78+frlL3+pV199VeHh4dYZrcPhUGhoqGw2m4qLi7V8+XKNHDlSI0eO1PLlyzV48GDl5ORYs3l5eSopKdGQIUMUFRWl0tJSjRkzRlOmTJEkjR49WtOmTVN+fr7Wrl0rSZo3b56ysrKUmJgoScrIyFBSUpJcLpdWrlyps2fPqrS0VPn5+QQYABAwnyrUx48fl8/n0xe/+EXt2bNHQ4cOtfaFhIQoJiZGQUFBl/18a9askSRNnDjRb/vPf/5z5ebmSpIWLVqkzs5OFRQUyO12KzU1VVVVVQoPD7fmV61apeDgYM2ePVudnZ2aPHmy1q9f77eWTZs2qaioyPp2eHZ2tlavXm3tDwoK0tatW1VQUKAJEyYoNDRUOTk5evrppy/7eAAAGGhGXUd9reM6auDq4DpqBEKgrqPu9+VZb731lrZv366WlhadP3/eb98PfvCDz7wwAADQz1C/8MIL+ta3vqXo6Gg5nc4+lzgRagAABka/Qr1s2TI9+eST1q/1BAAAV0a/rqN2u9164IEHBnotAACgl36F+oEHHlBVVdVArwUAAPTSr7e+R4wYoccee0y1tbUaM2aMBg0a5Le/qKhoQBYHAMD1rl+XZ/X+DWJ+T2iz6W9/+9tnWtS1isuzgKuDy7MQCNfU5VnHjx8f6HUAAICLMOrvUQMAAH/9OqN+8MEHL7n/Zz/7Wb8WAwAA/PUr1L3/pGR3d7caGhrU2tra779HDQAA+upXqLds2dJn2/nz51VQUKAvfvGLn3lRAADgQwP2GfXnPvc5fec739GqVasG6ikBALjuDeiXyd5++2198MEHA/mUAABc1/r11vfChQv97vt8PjU1NWnr1q2aO3fugCwMAAD0M9Rvvvmm3/3Pfe5zGjp0qJ555plP/EY4AAC4fP0K9R//+MeBXgcAALiIfoX6I6dPn9bRo0dls9k0atQoDR06dKDWBQAA1M8vk3V0dOjBBx9UXFyc7rzzTn3lK19RfHy88vLy9I9//GOg1wgAwHWrX6FeuHChduzYod/+9rdqbW1Va2urXn31Ve3YsUMlJSUDvUYAAK5b/Xrre/Pmzfr1r3+tiRMnWtu++tWvKjQ0VLNnz9aaNWsGan0AAFzX+nVG/Y9//EOxsbF9tsfExPDWNwAAA6hfoU5PT9fjjz+u999/39rW2dmpJ554Qunp6QO2OAAArnf9euv7ueee0/Tp03XTTTfplltukc1mU319vex2u6qqqgZ6jQAAXLf6FeoxY8bo2LFj+sUvfqEjR47I5/Ppa1/7mr7xjW8oNDR0oNcIAMB1q1+hLisrU2xsrPLz8/22/+xnP9Pp06e1ePHiAVkcAADXu359Rr127Vr9+7//e5/tX/rSl/TTn/70My8KAAB8qF+hbm5uVlxcXJ/tQ4cOVVNT02deFAAA+FC/Qp2QkKA33nijz/Y33nhD8fHxn3lRAADgQ/36jPqhhx5ScXGxuru7NWnSJEnSH/7wBy1atIjfTAYAwADqV6gXLVqks2fPqqCgQF1dXZKkG264QYsXL9aSJUsGdIEAAFzPbD6fz9ffB7e3t+vw4cMKDQ3VyJEjZbfbB3Jt15y2tjY5HA55PB5FREQEejnAv6zF6w4Fegm4Dq3ISwrI636mP3N544036rbbbhuotQAAgF769WUyAABwdRBqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMRqgBADAYoQYAwGCEGgAAgxFqAAAMFtBQ/+lPf9LMmTMVHx8vm82mV155xW9/bm6ubDab3y0tLc1vxuv1qrCwUNHR0QoLC1N2drZOnjzpN+N2u+VyueRwOORwOORyudTa2uo3c+LECc2cOVNhYWGKjo5WUVGRurq6rsRhAwBw2QIa6o6ODt1yyy1avXr1x85MmzZNTU1N1q2iosJvf3FxsbZs2aLy8nLV1NSovb1dWVlZ6unpsWZycnJUX1+vyspKVVZWqr6+Xi6Xy9rf09OjGTNmqKOjQzU1NSovL9fmzZtVUlIy8AcNAMCnEBzIF58+fbqmT59+yRm73S6n03nRfR6PR+vWrdPGjRs1ZcoUSdIvfvELJSQk6Pe//70yMzN1+PBhVVZWqra2VqmpqZKkF154Qenp6Tp69KgSExNVVVWlQ4cOqbGxUfHx8ZKkZ555Rrm5uXryyScVERExgEcNAMDlM/4z6u3btysmJkajRo1Sfn6+WlparH11dXXq7u5WRkaGtS0+Pl7JycnauXOnJGnXrl1yOBxWpCUpLS1NDofDbyY5OdmKtCRlZmbK6/Wqrq7uY9fm9XrV1tbmdwMAYCAZHerp06dr06ZNev311/XMM89o7969mjRpkrxerySpublZISEhioyM9HtcbGysmpubrZmYmJg+zx0TE+M3Exsb67c/MjJSISEh1szFlJWVWZ97OxwOJSQkfKbjBQCgt4C+9f1J5syZY/13cnKyxo0bp2HDhmnr1q267777PvZxPp9PNpvNun/hf3+Wmd6WLFmihQsXWvfb2tqINQBgQBl9Rt1bXFychg0bpmPHjkmSnE6nurq65Ha7/eZaWlqsM2Sn06lTp071ea7Tp0/7zfQ+c3a73eru7u5zpn0hu92uiIgIvxsAAAPpmgr1mTNn1NjYqLi4OElSSkqKBg0apOrqamumqalJDQ0NGj9+vCQpPT1dHo9He/bssWZ2794tj8fjN9PQ0KCmpiZrpqqqSna7XSkpKVfj0AAAuKiAvvXd3t6uv/71r9b948ePq76+XlFRUYqKitLSpUt1//33Ky4uTu+8844effRRRUdH695775UkORwO5eXlqaSkREOGDFFUVJRKS0s1ZswY61vgo0eP1rRp05Sfn6+1a9dKkubNm6esrCwlJiZKkjIyMpSUlCSXy6WVK1fq7NmzKi0tVX5+PmfJAICACmio9+3bp7vvvtu6/9HnvXPnztWaNWt04MABvfjii2ptbVVcXJzuvvtuvfzyywoPD7ces2rVKgUHB2v27Nnq7OzU5MmTtX79egUFBVkzmzZtUlFRkfXt8OzsbL9rt4OCgrR161YVFBRowoQJCg0NVU5Ojp5++ukr/SMAAOCSbD6fzxfoRfyraGtrk8PhkMfj4UwcuIIWrzsU6CXgOrQiLykgr3tNfUYNAMD1hlADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMECGuo//elPmjlzpuLj42Wz2fTKK6/47ff5fFq6dKni4+MVGhqqiRMn6uDBg34zXq9XhYWFio6OVlhYmLKzs3Xy5Em/GbfbLZfLJYfDIYfDIZfLpdbWVr+ZEydOaObMmQoLC1N0dLSKiorU1dV1JQ4bAIDLFtBQd3R06JZbbtHq1asvuv+pp57Ss88+q9WrV2vv3r1yOp2aOnWqzp07Z80UFxdry5YtKi8vV01Njdrb25WVlaWenh5rJicnR/X19aqsrFRlZaXq6+vlcrms/T09PZoxY4Y6OjpUU1Oj8vJybd68WSUlJVfu4AEAuAw2n8/nC/QiJMlms2nLli2aNWuWpA/PpuPj41VcXKzFixdL+vDsOTY2VitWrNDDDz8sj8ejoUOHauPGjZozZ44k6b333lNCQoIqKiqUmZmpw4cPKykpSbW1tUpNTZUk1dbWKj09XUeOHFFiYqK2bdumrKwsNTY2Kj4+XpJUXl6u3NxctbS0KCIi4rKOoa2tTQ6HQx6P57IfA+DTW7zuUKCXgOvQirykgLyusZ9RHz9+XM3NzcrIyLC22e123XXXXdq5c6ckqa6uTt3d3X4z8fHxSk5OtmZ27dolh8NhRVqS0tLS5HA4/GaSk5OtSEtSZmamvF6v6urqPnaNXq9XbW1tfjcAAAaSsaFubm6WJMXGxvptj42NtfY1NzcrJCREkZGRl5yJiYnp8/wxMTF+M71fJzIyUiEhIdbMxZSVlVmfezscDiUkJHzKowQA4NKMDfVHbDab332fz9dnW2+9Zy4235+Z3pYsWSKPx2PdGhsbL7kuAAA+LWND7XQ6JanPGW1LS4t19ut0OtXV1SW3233JmVOnTvV5/tOnT/vN9H4dt9ut7u7uPmfaF7Lb7YqIiPC7AQAwkIwN9fDhw+V0OlVdXW1t6+rq0o4dOzR+/HhJUkpKigYNGuQ309TUpIaGBmsmPT1dHo9He/bssWZ2794tj8fjN9PQ0KCmpiZrpqqqSna7XSkpKVf0OAEAuJTgQL54e3u7/vrXv1r3jx8/rvr6ekVFRenmm29WcXGxli9frpEjR2rkyJFavny5Bg8erJycHEmSw+FQXl6eSkpKNGTIEEVFRam0tFRjxozRlClTJEmjR4/WtGnTlJ+fr7Vr10qS5s2bp6ysLCUmJkqSMjIylJSUJJfLpZUrV+rs2bMqLS1Vfn4+Z8kAgIAKaKj37dunu+++27q/cOFCSdLcuXO1fv16LVq0SJ2dnSooKJDb7VZqaqqqqqoUHh5uPWbVqlUKDg7W7Nmz1dnZqcmTJ2v9+vUKCgqyZjZt2qSioiLr2+HZ2dl+124HBQVp69atKigo0IQJExQaGqqcnBw9/fTTV/pHAADAJRlzHfW/Aq6jBq4OrqNGIHAdNQAA6INQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQAwBgMKNDvXTpUtlsNr+b0+m09vt8Pi1dulTx8fEKDQ3VxIkTdfDgQb/n8Hq9KiwsVHR0tMLCwpSdna2TJ0/6zbjdbrlcLjkcDjkcDrlcLrW2tl6NQwQA4JKMDrUkfelLX1JTU5N1O3DggLXvqaee0rPPPqvVq1dr7969cjqdmjp1qs6dO2fNFBcXa8uWLSovL1dNTY3a29uVlZWlnp4eayYnJ0f19fWqrKxUZWWl6uvr5XK5rupxAgBwMcGBXsAnCQ4O9juL/ojP59Nzzz2n733ve7rvvvskSRs2bFBsbKx++ctf6uGHH5bH49G6deu0ceNGTZkyRZL0i1/8QgkJCfr973+vzMxMHT58WJWVlaqtrVVqaqok6YUXXlB6erqOHj2qxMTEq3ewAAD0YvwZ9bFjxxQfH6/hw4fra1/7mv72t79Jko4fP67m5mZlZGRYs3a7XXfddZd27twpSaqrq1N3d7ffTHx8vJKTk62ZXbt2yeFwWJGWpLS0NDkcDmsGAIBAMfqMOjU1VS+++KJGjRqlU6dOadmyZRo/frwOHjyo5uZmSVJsbKzfY2JjY/Xuu+9KkpqbmxUSEqLIyMg+Mx89vrm5WTExMX1eOyYmxpr5OF6vV16v17rf1tb26Q8SAIBLMDrU06dPt/57zJgxSk9P17/9279pw4YNSktLkyTZbDa/x/h8vj7beus9c7H5y3mesrIyPfHEE594HAAA9Jfxb31fKCwsTGPGjNGxY8esz617n/W2tLRYZ9lOp1NdXV1yu92XnDl16lSf1zp9+nSfs/XelixZIo/HY90aGxv7fWwAAFzMNRVqr9erw4cPKy4uTsOHD5fT6VR1dbW1v6urSzt27ND48eMlSSkpKRo0aJDfTFNTkxoaGqyZ9PR0eTwe7dmzx5rZvXu3PB6PNfNx7Ha7IiIi/G4AAAwko9/6Li0t1cyZM3XzzTerpaVFy5YtU1tbm+bOnSubzabi4mItX75cI0eO1MiRI7V8+XINHjxYOTk5kiSHw6G8vDyVlJRoyJAhioqKUmlpqcaMGWN9C3z06NGaNm2a8vPztXbtWknSvHnzlJWVxTe+AQABZ3SoT548qa9//ev6+9//rqFDhyotLU21tbUaNmyYJGnRokXq7OxUQUGB3G63UlNTVVVVpfDwcOs5Vq1apeDgYM2ePVudnZ2aPHmy1q9fr6CgIGtm06ZNKioqsr4dnp2drdWrV1/dgwUA4CJsPp/PF+hF/Ktoa2uTw+GQx+PhbXDgClq87lCgl4Dr0Iq8pIC87jX1GTUAANcbQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQg0AgMEINQAABiPUAAAYLDjQC8DHK9m+PdBLwHXqmYkTA70EAP/EGTUAAAYj1AAAGIxQAwBgMEINAIDBCDUAAAYj1AAAGIxQ9/Lf//3fGj58uG644QalpKToz3/+c6CXBAC4jhHqC7z88ssqLi7W9773Pb355pv6yle+ounTp+vEiROBXhoA4DpFqC/w7LPPKi8vTw899JBGjx6t5557TgkJCVqzZk2glwYAuE4R6n/q6upSXV2dMjIy/LZnZGRo586dAVoVAOB6x68Q/ae///3v6unpUWxsrN/22NhYNTc3X/QxXq9XXq/Xuu/xeCRJbW1tA7Imb0fHgDwP8GkN1P8NXynezvZALwHXoSvx7yI8PFw2m+2SM4S6l94/MJ/P97E/xLKyMj3xxBN9tickJFyRtQFXy/8L9AIAAz1fOPDP6fF4FBERcckZQv1P0dHRCgoK6nP23NLS0ucs+yNLlizRwoULrfvnz5/X2bNnNWTIkE/8X0i4stra2pSQkKDGxsZP/EcAXC/4d2Ge8PDwT5wh1P8UEhKilJQUVVdX695777W2V1dX65577rnoY+x2u+x2u9+2z3/+81dymfiUIiIi+H9IQC/8u7i2EOoLLFy4UC6XS+PGjVN6err+53/+RydOnNAjjzwS6KUBAK5ThPoCc+bM0ZkzZ/TDH/5QTU1NSk5OVkVFhYYNGxbopQEArlOEupeCggIVFBQEehn4jOx2ux5//PE+H00A1zP+XVybbD6fzxfoRQAAgIvjF54AAGAwQg0AgMEINQAABiPUAAAYjFADAGAwQo1rysSJE7VgwQItWLBAn//85zVkyBB9//vf10cXL7jdbn3zm99UZGSkBg8erOnTp+vYsWPW4999913NnDlTkZGRCgsL05e+9CVVVFQE6nCAz2zixIkqKirSokWLFBUVJafTqaVLl1r7PR6P5s2bp5iYGEVERGjSpEn6y1/+4vccy5YtU0xMjMLDw/XQQw/pu9/9rm699dareyD4WIQa15wNGzYoODhYu3fv1o9//GOtWrVK//u//ytJys3N1b59+/Taa69p165d8vl8+upXv6ru7m5J0vz58+X1evWnP/1JBw4c0IoVK3TjjTcG8nCAz2zDhg0KCwvT7t279dRTT+mHP/yhqqur5fP5NGPGDDU3N6uiokJ1dXX68pe/rMmTJ+vs2bOSpE2bNunJJ5/UihUrVFdXp5tvvllr1qwJ8BHhQlxHjWvKxIkT1dLSooMHD1p/+OS73/2uXnvtNb366qsaNWqU3njjDY0fP16SdObMGSUkJGjDhg164IEHNHbsWN1///16/PHHA3kYwICZOHGienp69Oc//9nadvvtt2vSpEnKyMjQvffeq5aWFr9fcjJixAgtWrRI8+bNU1pamsaNG6fVq1db+++44w61t7ervr7+ah4KPgZn1LjmpKWl+f11svT0dB07dkyHDh1ScHCwUlNTrX1DhgxRYmKiDh8+LEkqKirSsmXLNGHCBD3++OPav3//VV8/MNDGjh3rdz8uLk4tLS2qq6tTe3u7hgwZohtvvNG6HT9+XG+//bYk6ejRo7r99tv9Ht/7PgKLXyGKf3kX/k3xhx56SJmZmdq6dauqqqpUVlamZ555RoWFV+APzQJXyaBBg/zu22w2nT9/XufPn1dcXJy2b9/e5zEX/qW/3n+WlzdazcIZNa45tbW1fe6PHDlSSUlJ+uCDD7R7925r35kzZ/TWW29p9OjR1raEhAQ98sgj+s1vfqOSkhK98MILV23twNX05S9/Wc3NzQoODtaIESP8btHR0ZKkxMRE7dmzx+9x+/btC8Ry8TEINa45jY2NWrhwoY4ePaqXXnpJP/nJT/Ttb39bI0eO1D333KP8/HzV1NToL3/5i/7zP/9TX/jCF6y/KV5cXKzf/e53On78uP7v//5Pr7/+ul/EgX8lU6ZMUXp6umbNmqXf/e53euedd7Rz5059//vft2JcWFiodevWacOGDTp27JiWLVum/fv39znLRuDw1jeuOd/85jfV2dmp22+/XUFBQSosLNS8efMkST//+c/17W9/W1lZWerq6tKdd96piooK663Bnp4ezZ8/XydPnlRERISmTZumVatWBfJwgCvGZrOpoqJC3/ve9/Tggw/q9OnTcjqduvPOOxUbGytJ+sY3vqG//e1vKi0t1fvvv6/Zs2crNze3z1k2AodvfeOaMnHiRN1666167rnnAr0U4F/W1KlT5XQ6tXHjxkAvBeKMGgCua//4xz/005/+VJmZmQoKCtJLL72k3//+96qurg700vBPhBoArmMfvT2+bNkyeb1eJSYmavPmzZoyZUqgl4Z/4q1vAAAMxre+AQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEG0G/vvPOObDYbfw4RuIIINQAABiPUAAAYjFAD+ETnz5/XihUrNGLECNntdt1888168skn+8z19PQoLy9Pw4cPV2hoqBITE/X888/7zWzfvl233367wsLC9PnPf14TJkzQu+++K0n6y1/+orvvvlvh4eGKiIhQSkoKf3IR1z1+hSiAT7RkyRK98MILWrVqle644w41NTXpyJEjfebOnz+vm266Sb/61a8UHR2tnTt3at68eYqLi9Ps2bP1wQcfaNasWcrPz9dLL72krq4u7dmzx/qTit/4xjf0H//xH1qzZo2CgoJUX19v/eUz4HrFrxAFcEnnzp3T0KFDtXr1aj300EN++9555x0NHz5cb775pm699daLPn7+/Pk6deqUfv3rX+vs2bMaMmSItm/frrvuuqvPbEREhH7yk59o7ty5V+JQgGsSb30DuKTDhw/L6/Vq8uTJlzX/05/+VOPGjdPQoUN144036oUXXtCJEyckSVFRUcrNzVVmZqZmzpyp559/Xk1NTdZjFy5cqIceekhTpkzRj370I7399ttX5JiAawmhBnBJoaGhlz37q1/9St/5znf04IMPqqqqSvX19fqv//ovdXV1WTM///nPtWvXLo0fP14vv/yyRo0apdraWknS0qVLdfDgQc2YMUOvv/66kpKStGXLlgE/JuBawlvfAC7p/fffV1RUlH784x9/4lvfhYWFOnTokP7whz9YM1OmTNHf//73j73WOj09Xbfddpt+/OMf99n39a9/XR0dHXrttdcG9JiAawln1AAu6YYbbtDixYu1aNEivfjii3r77bdVW1urdevW9ZkdMWKE9u3bp9/97nd666239Nhjj2nv3r3W/uPHj2vJkiXatWuX3n33XVVVVemtt97S6NGj1dnZqQULFmj79u1699139cYbb2jv3r0aPXr01TxcwDh86xvAJ3rssccUHBysH/zgB3rvvfcUFxenRx55pM/cI488ovr6es2ZM0c2m01f//rXVVBQoG3btkmSBg8erCNHjmjDhg06c+aM4uLitGDBAj388MP64IMPdObMGX3zm9/UqVOnFB0drfvuu09PPPHE1T5cwCi89Q0AgMF46xsAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBghBoAAIMRagAADEaoAQAwGKEGAMBg/x/nzBpZyWtWYQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 1000, Negative: 35188\n"
     ]
    }
   ],
   "source": [
    "## Visualisation of unique Values in the Target Variable 'class'\n",
    "\n",
    "pos = df[df['class']== 'pos'].shape[0]\n",
    "neg = df[df['class']== 'neg'].shape[0]\n",
    "\n",
    "sns.catplot(data= df, x='class', kind='count', palette = 'winter_r', alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "print('Positive: '+str(pos) + ', Negative: '+str(neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60169e1",
   "metadata": {},
   "source": [
    "Here, we can see that there is an imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69674190",
   "metadata": {},
   "source": [
    "**Report**\n",
    "- The target classes are highly imbalanced\n",
    "- Class imbalance is a scenario that arises when we have unequal distribution of class in a dataset i.e. the no. of data points in the negative class (majority class) very large compared to that of the positive class (minority class)\n",
    "- If the imbalanced data is not treated beforehand, then this will degrade the performance of the classifier model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23315bc8",
   "metadata": {},
   "source": [
    "**How to handle Imbalance Data ?**\n",
    "\n",
    "- Resampling data is one of the most commonly preferred approaches to deal with an imbalanced dataset. There are broadly two types of methods for this i) Undersampling ii) Oversampling. In most cases, oversampling is preferred over undersampling techniques. The reason being, in undersampling we tend to remove instances from data that may be carrying some important information.\n",
    "- **SMOTE:** Synthetic Minority Oversampling Technique\n",
    "- SMOTE is an oversampling technique where the synthetic samples are generated for the minority class.\n",
    "- Hybridization techniques involve combining both undersampling and oversampling techniques. This is done to optimize the performance of classifier models for the samples created as part of these techniques.\n",
    "- It only duplicates the data and it won't add and new information. Hence we look at some different techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dce9fce",
   "metadata": {},
   "source": [
    "## Create Functions for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a2857fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(true, predicted):\n",
    "    \n",
    "    '''\n",
    "    This function takes the true value (y_true) and predicted value (y_pred)\n",
    "    and returns the measure of Evaluation metrics such as accuracy, f1-score, precision, recall, roc_auc\n",
    "    '''\n",
    "    \n",
    "    acc = accuracy_score(true, predicted) # calculating the Accuracy of the model\n",
    "    f1 = f1_score(true, predicted) # calculating the F1 score\n",
    "    precision = precision_score(true, predicted) # calculating the precision score\n",
    "    recall = recall_score(true, predicted) # calculating the recall \n",
    "    roc_auc = roc_auc_score(true, predicted) # calculate the ROC and AUC value\n",
    "    \n",
    "    return acc, f1, precision, recall, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2b1f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(y_true, y_pred):\n",
    "    '''\n",
    "    it takes y_true, y_pred and prints Total cost due to misclassification\n",
    "    '''\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = 10 * fp + 500 * fn\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b17a10",
   "metadata": {},
   "source": [
    "#### what does ravel() do?\n",
    "\n",
    "- The ravel() function in NumPy is used to flatten multi-dimensional arrays into a one-dimensional array. \n",
    "- When applied to a multi-dimensional array, ravel() returns a flattened view of the array, meaning it returns a new array that contains the same data as the original array but reshaped into a one-dimensional array.\n",
    "- In the context of confusion matrices in scikit-learn, the confusion matrix is typically a 2x2 array where rows represent actual classes and columns represent predicted classes.\n",
    "- When you apply ravel() to the confusion matrix obtained from confusion_matrix(), it flattens this 2x2 array into a one-dimensional array, resulting in an array with the counts of TN, FP, FN, and TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e184c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function which can evaluate models and return a report summary\n",
    "\n",
    "def evaluation_models(X, y, models):\n",
    "    \n",
    "    # split the dataset into train and test\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    # creating an empty array\n",
    "    cost_list = []\n",
    "    models_list = []\n",
    "    accuracy_list =[]\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, Y_train) # training the model\n",
    "        \n",
    "        # Make the prediction\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Training set performance\n",
    "        model_train_accuracy, model_train_f1, model_train_precision,\\\n",
    "        model_train_recall, model_train_roc_auc_score = evaluate_clf(Y_train, Y_train_pred)\n",
    "        train_cost = total_cost(Y_train, Y_train_pred)\n",
    "        \n",
    "        # Testing set performnace \n",
    "        model_test_accuracy, model_test_f1, model_test_precision,\\\n",
    "        model_test_recall, model_test_roc_auc_score = evaluate_clf(Y_test, Y_test_pred)\n",
    "        test_cost = total_cost(Y_test, Y_test_pred)\n",
    "        \n",
    "        print(list(model.keys())[i])\n",
    "        model_list.append(list(models.keys())[i])\n",
    "        \n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_train_f1)) \n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_train_rocauc_score))\n",
    "        print(f'- COST: {train_cost}.')\n",
    "\n",
    "        print('----------------------------------')\n",
    "\n",
    "        print('Model performance for Test set')\n",
    "        print('- Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('- F1 score: {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- Roc Auc Score: {:.4f}'.format(model_test_rocauc_score))\n",
    "        print(f'- COST: {test_cost}.')\n",
    "        cost_list.append(test_cost)\n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "        \n",
    "    report = pd.DataFrame(list(zip(model_list, cost_list)))\n",
    "    \n",
    "    return report   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64079e2a",
   "metadata": {},
   "source": [
    "### Plot  distribution of all Independent Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1eafa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnumeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\\n\\nplt.figure(figsize=(15,125))\\n\\nfor i, col in enumerate(numeric_features):\\n    plt.subplot(60, 3, i+1)\\n    sns.distplot(x=df[col], color = 'indianred')\\n    plt.xlabel(col, weight='bold')\\n    plt.tight_layout()\\n    \\n    \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "\n",
    "plt.figure(figsize=(15,125))\n",
    "\n",
    "for i, col in enumerate(numeric_features):\n",
    "    plt.subplot(60, 3, i+1)\n",
    "    sns.distplot(x=df[col], color = 'indianred')\n",
    "    plt.xlabel(col, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68faebd",
   "metadata": {},
   "source": [
    "**Report**\n",
    "- As per the above plot most of the features are not normally distributed.\n",
    "- Transformation of data is not of prime importance since it is a classification problem.\n",
    "- Interpreting each and every column is not necessary as this is sensor data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3559f",
   "metadata": {},
   "source": [
    "## Evaluate Model on Different experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "200dd83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>ag_004</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153204</td>\n",
       "      <td>1.820000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11804.0</td>\n",
       "      <td>684444.0</td>\n",
       "      <td>...</td>\n",
       "      <td>129862.0</td>\n",
       "      <td>26872.0</td>\n",
       "      <td>34044.0</td>\n",
       "      <td>22472.0</td>\n",
       "      <td>34362.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>453236</td>\n",
       "      <td>2.926000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>323436.0</td>\n",
       "      <td>2999280.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7908038.0</td>\n",
       "      <td>3026002.0</td>\n",
       "      <td>5025350.0</td>\n",
       "      <td>2025766.0</td>\n",
       "      <td>1160638.0</td>\n",
       "      <td>533834.0</td>\n",
       "      <td>493800.0</td>\n",
       "      <td>6914.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72504</td>\n",
       "      <td>1.594000e+03</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>178226.0</td>\n",
       "      <td>1249396.0</td>\n",
       "      <td>3813464.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1432098.0</td>\n",
       "      <td>372252.0</td>\n",
       "      <td>527514.0</td>\n",
       "      <td>358274.0</td>\n",
       "      <td>332818.0</td>\n",
       "      <td>284178.0</td>\n",
       "      <td>3742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>762958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>776.0</td>\n",
       "      <td>281128.0</td>\n",
       "      <td>2186308.0</td>\n",
       "      <td>8123016.0</td>\n",
       "      <td>18022646.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>695994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55620.0</td>\n",
       "      <td>1190014.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1397742.0</td>\n",
       "      <td>495544.0</td>\n",
       "      <td>361646.0</td>\n",
       "      <td>28610.0</td>\n",
       "      <td>5130.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36183</th>\n",
       "      <td>153002</td>\n",
       "      <td>6.640000e+02</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2564.0</td>\n",
       "      <td>59100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>998500.0</td>\n",
       "      <td>566884.0</td>\n",
       "      <td>1290398.0</td>\n",
       "      <td>1218244.0</td>\n",
       "      <td>1019768.0</td>\n",
       "      <td>717762.0</td>\n",
       "      <td>898642.0</td>\n",
       "      <td>28588.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36184</th>\n",
       "      <td>2286</td>\n",
       "      <td>2.130707e+09</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10578.0</td>\n",
       "      <td>6760.0</td>\n",
       "      <td>21126.0</td>\n",
       "      <td>68424.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36185</th>\n",
       "      <td>112</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>...</td>\n",
       "      <td>792.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36186</th>\n",
       "      <td>80292</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>...</td>\n",
       "      <td>699352.0</td>\n",
       "      <td>222654.0</td>\n",
       "      <td>347378.0</td>\n",
       "      <td>225724.0</td>\n",
       "      <td>194440.0</td>\n",
       "      <td>165070.0</td>\n",
       "      <td>802280.0</td>\n",
       "      <td>388422.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36187</th>\n",
       "      <td>40222</td>\n",
       "      <td>6.980000e+02</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>440066.0</td>\n",
       "      <td>183200.0</td>\n",
       "      <td>344546.0</td>\n",
       "      <td>254068.0</td>\n",
       "      <td>225148.0</td>\n",
       "      <td>158304.0</td>\n",
       "      <td>170384.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36188 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa_000        ac_000  ad_000  ae_000  af_000  ag_000    ag_001  \\\n",
       "0      153204  1.820000e+02     NaN     0.0     0.0     0.0       0.0   \n",
       "1      453236  2.926000e+03     NaN     0.0     0.0     0.0       0.0   \n",
       "2       72504  1.594000e+03  1052.0     0.0     0.0     0.0     244.0   \n",
       "3      762958           NaN     NaN     NaN     NaN   776.0  281128.0   \n",
       "4      695994           NaN     NaN     NaN     NaN     0.0       0.0   \n",
       "...       ...           ...     ...     ...     ...     ...       ...   \n",
       "36183  153002  6.640000e+02   186.0     0.0     0.0     0.0       0.0   \n",
       "36184    2286  2.130707e+09   224.0     0.0     0.0     0.0       0.0   \n",
       "36185     112  2.130706e+09    18.0     0.0     0.0     0.0       0.0   \n",
       "36186   80292  2.130706e+09   494.0     0.0     0.0     0.0       0.0   \n",
       "36187   40222  6.980000e+02   628.0     0.0     0.0     0.0       0.0   \n",
       "\n",
       "          ag_002     ag_003      ag_004  ...     ee_002     ee_003     ee_004  \\\n",
       "0            0.0    11804.0    684444.0  ...   129862.0    26872.0    34044.0   \n",
       "1          222.0   323436.0   2999280.0  ...  7908038.0  3026002.0  5025350.0   \n",
       "2       178226.0  1249396.0   3813464.0  ...  1432098.0   372252.0   527514.0   \n",
       "3      2186308.0  8123016.0  18022646.0  ...        NaN        NaN        NaN   \n",
       "4            0.0    55620.0   1190014.0  ...  1397742.0   495544.0   361646.0   \n",
       "...          ...        ...         ...  ...        ...        ...        ...   \n",
       "36183        0.0     2564.0     59100.0  ...   998500.0   566884.0  1290398.0   \n",
       "36184        0.0        0.0       104.0  ...    10578.0     6760.0    21126.0   \n",
       "36185        0.0        0.0        28.0  ...      792.0      386.0      452.0   \n",
       "36186        0.0        0.0       330.0  ...   699352.0   222654.0   347378.0   \n",
       "36187        0.0        0.0      1226.0  ...   440066.0   183200.0   344546.0   \n",
       "\n",
       "          ee_005     ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
       "0        22472.0    34362.0       0.0       0.0       0.0     0.0     0.0  \n",
       "1      2025766.0  1160638.0  533834.0  493800.0    6914.0     0.0     0.0  \n",
       "2       358274.0   332818.0  284178.0    3742.0       0.0     0.0     0.0  \n",
       "3            NaN        NaN       NaN       NaN       NaN     NaN     NaN  \n",
       "4        28610.0     5130.0     212.0       0.0       0.0     NaN     NaN  \n",
       "...          ...        ...       ...       ...       ...     ...     ...  \n",
       "36183  1218244.0  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
       "36184    68424.0      136.0       0.0       0.0       0.0     0.0     0.0  \n",
       "36185      144.0      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
       "36186   225724.0   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
       "36187   254068.0   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
       "\n",
       "[36188 rows x 163 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting X and Y for all Experiments\n",
    "\n",
    "X = df.drop('class', axis = 1)\n",
    "Y = df['class']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbf67b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "36183    0\n",
       "36184    0\n",
       "36185    0\n",
       "36186    0\n",
       "36187    0\n",
       "Name: class, Length: 36188, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually mapping the target variable instad of performing LabelEncoder, One-hot encoding\n",
    "\n",
    "Y = Y.replace({'pos' : 1, 'neg' : 0})\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58194d5",
   "metadata": {},
   "source": [
    "### Experiment: 1 = KNN Imputer for Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bbee3e",
   "metadata": {},
   "source": [
    "**what is Robust scaler?**\n",
    "\n",
    "- The Robust Scaler is a data preprocessing technique used in machine learning to scale features (variables) so that they're centered around median and scaled according to the Interquartile Range (IQR).\n",
    "\n",
    "- This scaling method is robust to outliers in the data, meaning it can handle instances where outliers are present without skewing the scaling process significantly.\n",
    "\n",
    "-  The Robust Scaler subtracts the median value of each feature from the data. This ensures that the scaled data is centered around zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7f05b",
   "metadata": {},
   "source": [
    "**Why Robust scaler and not Standard scaler?**\n",
    "- Scaling the data using Robust scaler\n",
    "- Since most of the independent variables are not normally distributed we cannot use Standardscaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3355c5",
   "metadata": {},
   "source": [
    "**Why Robust Scaler and not Minmax?** \n",
    "- because most of the feature has outliers. So Minmax will scale data according to Max values which is outlier.\n",
    "- This Scaler removes the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range). The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94a37320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the robust scaler for KNN best selection experiment\n",
    "\n",
    "robustscaler = RobustScaler()\n",
    "\n",
    "X1 = robustscaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe65075e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.48316651e+00,  3.16455696e-02,             nan, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 8.58106804e+00,  2.92616034e+00,             nan, ...,\n",
       "         3.42616452e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 8.43005945e-01,  1.52109705e+00,  2.26470588e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-6.28301407e-01,  2.24758046e+06, -2.69607843e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.00129058e+00,  2.24758046e+06,  8.97058824e-01, ...,\n",
       "         1.92478692e+02,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.86901072e-01,  5.75949367e-01,  1.22549020e+00, ...,\n",
       "         7.82953419e-02,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c1f839",
   "metadata": {},
   "source": [
    "**What is KNN Imputer?**\n",
    "\n",
    "- The KNN (K-Nearest Neighbors) imputer is a technique used to impute (fill in) missing values in a dataset by using the information from the dataset itself. \n",
    "\n",
    "- KNN imputation works by finding the k nearest neighbors for each observation with missing values and then averaging or taking a weighted average of those neighbors' values to impute the missing value.\n",
    "\n",
    "- KNNImputer helps to impute missing values present in the observations by finding the nearest neighbors with the Euclidean distance matrix.\n",
    "\n",
    "- Here we Iterates through different K values and get accuracy and choose best K values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d52aa38",
   "metadata": {},
   "source": [
    "#### Finding the optimal n_neighbour value for KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b38e588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nresults = []\\n\\n#define imputer\\nimputer = KNNImputer(n_neighbors= 5, weights = 'uniform', metric = 'nan_euclidean')\\n\\n# different values of parameter\\nstrategies = [str(i) for i in [1,3,5,7,9]]\\n\\nfor s in strategies:\\n    pipeline = Pipeline(steps = [('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\\n    scores = cross_val_score(pipeline, X1, Y, scoring = 'accuracy', cv = 2, n_jobs=-1)\\n    results.append(scores)\\n    print('n_neighbors= %s || accuracy (%.4f)' % (s , mean(scores)))\\n    \\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "results = []\n",
    "\n",
    "#define imputer\n",
    "imputer = KNNImputer(n_neighbors= 5, weights = 'uniform', metric = 'nan_euclidean')\n",
    "\n",
    "# different values of parameter\n",
    "strategies = [str(i) for i in [1,3,5,7,9]]\n",
    "\n",
    "for s in strategies:\n",
    "    pipeline = Pipeline(steps = [('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\n",
    "    scores = cross_val_score(pipeline, X1, Y, scoring = 'accuracy', cv = 2, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    print('n_neighbors= %s || accuracy (%.4f)' % (s , mean(scores)))\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31138c",
   "metadata": {},
   "source": [
    "**We can observe n_neighbors = 3 is able to produce the highest accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce0319b",
   "metadata": {},
   "source": [
    "### Pipeline for KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2fdf7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude='object').columns\n",
    "\n",
    "# fit the KNN imputer with selected K-value\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=3)),\n",
    "    ('RobustScaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07311f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_knn = knn_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c816a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "# Fit the model to generate the data.\n",
    "X_res, y_res = smt.fit_resample(X_knn, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc997cf3",
   "metadata": {},
   "source": [
    "**handling The Imbalanced data**\n",
    "\n",
    " **SMOTE+TOMEK** is one of such a hybrid technique that aims to clean overlapping data points for each of the classes distributed in sample space.\n",
    " \n",
    " - This method combines the SMOTE ability to generate synthetic data for minority class and Tomek Links ability to remove the data that are identified as Tomek links from the majority class\n",
    " \n",
    " - To add new data of minority class\n",
    " 1. Choose random data from the minority class.\n",
    " 2. Calculate the distance between the random data and its k nearest neighbors.\n",
    " 3. Multiply the difference with a random number between 0 and 1, then add the result to the minority class as a synthetic sample.\n",
    " 4. Repeat step number 2â€“3 until the desired proportion of minority class is met.\n",
    " \n",
    " - To remove the tomek links of the majority class\n",
    " 1. Choose random data from the majority class.\n",
    " 2. If the random dataâ€™s nearest neighbor is the data from the minority class (i.e. create the Tomek Link), then remove the Tomek Link.\n",
    " \n",
    " - This is method instead of adding duplicate data it synthesises the new data based on the already avalialble classes. Hence we choose this as our imputer method for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2c87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
